{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "view-in-github",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/calvinli2024/mitbforalldemo/blob/main/fine_tuning/bert-fine-tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da0d36",
   "metadata": {
    "id": "84da0d36"
   },
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this notebook is to experiment with building a multilabel classifier in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e030f",
   "metadata": {
    "id": "f82e030f"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c78d5b",
   "metadata": {
    "id": "08c78d5b"
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c489e5f",
   "metadata": {
    "id": "4c489e5f"
   },
   "outputs": [],
   "source": [
    "%pip install datasets transformers torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf28e89",
   "metadata": {
    "id": "3cf28e89"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c22f7c",
   "metadata": {
    "id": "f2c22f7c"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast, TrainingArguments, Trainer, EvalPrediction\n",
    "from datasets import load_dataset, Features, Value, Sequence\n",
    "import pandas as pd\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torch.cuda import empty_cache\n",
    "from torch import from_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452af26",
   "metadata": {
    "id": "d452af26"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LlQpwS2ieRKI",
   "metadata": {
    "id": "LlQpwS2ieRKI"
   },
   "source": [
    "### Philosophy Schools Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mztc0tbRZ_uO",
   "metadata": {
    "id": "mztc0tbRZ_uO"
   },
   "outputs": [],
   "source": [
    "phil_ds = load_dataset(\"maximuspowers/philosophy-schools-multilabel\", split=\"train\")\n",
    "\n",
    "remove_cols = [\"title\", \"description\", \"link\", \"source\", \"philosophy_schools\"]\n",
    "\n",
    "phil_ds = phil_ds.remove_columns(remove_cols)\n",
    "\n",
    "label_cols = [col for col in phil_ds.features.keys() if col != 'summary']\n",
    "\n",
    "id2label = {idx:label for idx, label in enumerate(label_cols)}\n",
    "label2id = {label:idx for idx, label in enumerate(label_cols)}\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0d0de",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c9b84",
   "metadata": {
    "id": "9a0c9b84"
   },
   "outputs": [],
   "source": [
    "def encode_data(data):\n",
    "  summaries = data[\"summary\"]\n",
    "\n",
    "  encoding = tokenizer(summaries, truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "  labels = pd.DataFrame({})\n",
    "  for idx, label_col in enumerate(label_cols):\n",
    "    labels.loc[:, label_col] = data[label_col]\n",
    "\n",
    "  encoding[\"labels\"] = labels.values.tolist()\n",
    "\n",
    "  return encoding\n",
    "\n",
    "encoded_dataset = phil_ds.map(encode_data, batched=True, remove_columns=phil_ds.column_names)\n",
    "\n",
    "encoded_dataset.set_format(\"torch\")\n",
    "\n",
    "encoded_dataset = encoded_dataset.cast(Features({\n",
    "  \"labels\": Sequence(Value(\"float32\")),\n",
    "  \"input_ids\": Sequence(Value(\"int32\")),\n",
    "  \"attention_mask\": Sequence(Value(\"int8\"))\n",
    "}))\n",
    "\n",
    "train_valid_split = encoded_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2078d",
   "metadata": {
    "id": "41e2078d"
   },
   "source": [
    "## MultiLabel Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efbf733",
   "metadata": {
    "id": "3efbf733"
   },
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "  \"distilbert/distilbert-base-uncased\",\n",
    "  num_labels=len(label_cols),\n",
    "  problem_type=\"multi_label_classification\",\n",
    "  id2label=id2label,\n",
    "  label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75dcd43",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de21cc",
   "metadata": {},
   "source": [
    "## Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X_mBcrvFBHGr",
   "metadata": {
    "id": "X_mBcrvFBHGr"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(ep: EvalPrediction):\n",
    "  metric = MultilabelF1Score(num_labels=len(label_cols))\n",
    "\n",
    "  f1 = metric(from_numpy(ep.predictions), from_numpy(ep.label_ids))\n",
    "\n",
    "  return {\"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c3b2b9",
   "metadata": {},
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6flRKm4N_kvG",
   "metadata": {
    "id": "6flRKm4N_kvG"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"bert-fine-tuning\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=0.001,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d7d31",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_cache()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_valid_split[\"train\"],\n",
    "    eval_dataset=train_valid_split[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fine_tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
